## 数据准备

数据准备过程是从数据收集开始的，通常我们将其称为ETL过程（Extract Transform Load）。我们可能需要操作多个一对一，一对多或多对多的关系表，将不同来源的数据整合在一起，通过KEY 键将数据汇聚成所需的分析级别。

## 数据整合

## 数据清洗

数据清洗是整合数据后所需要进行的数据预处理工作。在这一步，我们将脏数据清理为相对比较规整的数据，数据如果不清洗，那很可能是garbage in & garbage out了。

不同的数据，可能有不同的清洗方法，但无论是何种数据，在整个数据清洗过程中，总是有那么一些步骤和方法是通用的，例如缺失值分析和处理。

数据清洗的主要包括：纠正错误、删除重复项、统一规格、修正逻辑、转换构造、数据压缩、补足残缺/空值、丢弃数据/变量。

1. **分析数据**

   　　在实际项目中，当我们确定需求后就会去找相应的数据，拿到数据后，首先要对数据进行描述性统计分析，查看哪些数据是不合理的，也可以知道数据的基本情况。

2. **缺失值处理**

3. **异常值处理**

4. **去重处理**

5. **噪音处理**

   分箱 或者 回归

   

1. **数据怎么清洗，缺失值怎么填充**
   1. [数据挖掘中常用的数据清洗方法有哪些？](https://www.zhihu.com/question/22077960)
   2. [机器学习基础与实践（一）----数据清洗](https://www.cnblogs.com/charlotte77/p/5606926.html)
   3. 删除缺失值
   4. 均值填补法
   5. 热卡填补法
      1. 在数据库中找到一个与它最相似的对象，然后用这个相似对象的值来进行填充。
   6. 还有类似于最近距离决定填补法、回归填补法、多重填补方法、K-最近邻法、有序最近邻法、基于贝叶斯的方法等
2. 

## 数据转换

1. 分箱

   ```python
   # pandas one-hot编码
   df = pd.get_dummies(df,columns=['job','class'],drop_first=0)
   # columns表示你要引入分箱的变量，drop_first=0 代表使用 n-1个虚拟变量
   
   # 有序变量分箱
   dic_blood = {'正常':0,'正常高值':1,'1级高血压':2,'2级高血压':3,'3级高血压':4}
   df['blood_pressure_enc'] = df['blood_pressure'].map(dic_blood)
   
   # 连续变量分箱
   df['age_bin_1'] = pd.qcut(df['age'],3) #新增一列存储等频划分的分箱特征
   df['age_bin_2'] = pd.cut(df['age'],3)  #新增一列存储等距划分的分箱特征
   ```

2. 

3. 

## 探索性数据分析